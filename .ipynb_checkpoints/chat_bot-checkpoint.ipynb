{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa464063-90a1-4353-8206-62819c43c82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:25:47.168105Z",
     "iopub.status.busy": "2024-10-09T11:25:47.166778Z",
     "iopub.status.idle": "2024-10-09T11:25:47.189079Z",
     "shell.execute_reply": "2024-10-09T11:25:47.188078Z",
     "shell.execute_reply.started": "2024-10-09T11:25:47.166778Z"
    }
   },
   "outputs": [],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1acdad67-be4e-483d-9b00-299739f139a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:19:49.023451Z",
     "iopub.status.busy": "2024-10-09T11:19:49.022488Z",
     "iopub.status.idle": "2024-10-09T11:19:49.043447Z",
     "shell.execute_reply": "2024-10-09T11:19:49.042450Z",
     "shell.execute_reply.started": "2024-10-09T11:19:49.023451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73cb8c-0574-4721-aad7-d493a069a7f1",
   "metadata": {},
   "source": [
    "## Web Scraping with ScrapeWebsiteTool\n",
    "\n",
    "In this section, we utilize the `ScrapeWebsiteTool` to extract content from a specified website. This tool is instrumental for gathering relevant information during the execution of our project, particularly for analyzing text data from web sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ca76702-1f98-4267-a116-280399694509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:19:49.718919Z",
     "iopub.status.busy": "2024-10-09T11:19:49.717787Z",
     "iopub.status.idle": "2024-10-09T11:19:49.860009Z",
     "shell.execute_reply": "2024-10-09T11:19:49.858005Z",
     "shell.execute_reply.started": "2024-10-09T11:19:49.718919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Read website content\n"
     ]
    }
   ],
   "source": [
    "# To enable scrapping any website it finds during it's execution\n",
    "tool = ScrapeWebsiteTool()\n",
    "\n",
    "# Initialize the tool with the website URL, so the agent can only scrap the content of the specified website\n",
    "tool = ScrapeWebsiteTool(website_url='https://animemangatoon.com/castle-swimmer-unveiling-new-prophecy/')\n",
    "\n",
    "# Extract the text from the site\n",
    "text = tool.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682765c7-3a23-458e-a207-609821f459d7",
   "metadata": {},
   "source": [
    "## Text Chunking with `get_text_chunks`\n",
    "\n",
    "The `get_text_chunks` function is designed to split a large body of text into smaller, more manageable chunks. This is especially useful for processing long documents, enabling more efficient analysis, and ensuring that text fits within model input limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e43fe5-10bf-4b60-b9ec-222bf17b75cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:20:03.685093Z",
     "iopub.status.busy": "2024-10-09T11:20:03.685093Z",
     "iopub.status.idle": "2024-10-09T11:20:03.697286Z",
     "shell.execute_reply": "2024-10-09T11:20:03.696289Z",
     "shell.execute_reply.started": "2024-10-09T11:20:03.685093Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05870a8-6db3-4550-bded-832f49db7bd7",
   "metadata": {},
   "source": [
    "## Vector Store Creation with `get_vector_store`\n",
    "\n",
    "The `get_vector_store` function is designed to create a vector store from a list of text chunks. This is particularly useful for natural language processing tasks where you need to convert text data into numerical representations (embeddings) for efficient searching and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4efedcf4-9204-41e8-b6f7-afe01d11cf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:20:04.326845Z",
     "iopub.status.busy": "2024-10-09T11:20:04.325335Z",
     "iopub.status.idle": "2024-10-09T11:20:04.335848Z",
     "shell.execute_reply": "2024-10-09T11:20:04.334884Z",
     "shell.execute_reply.started": "2024-10-09T11:20:04.326845Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vector_store(text_chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    try:\n",
    "        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "        return vector_store\n",
    "    except IndexError as e:\n",
    "        raise IndexError(f\"An error occurred during vector store creation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9bbcb-c705-4bd9-b3cb-ba9a13c3354e",
   "metadata": {},
   "source": [
    "## Conversational Chain with `get_conversational_chain`\n",
    "\n",
    "The `get_conversational_chain` function is designed to create a question-answering (QA) chain that utilizes a generative AI model to extract and summarize relevant information from a given context. This function is useful for building interactive applications that require understanding and responding to user queries based on provided text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "714dced3-a924-4a25-81a5-0a02ac607492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:27:04.680795Z",
     "iopub.status.busy": "2024-10-09T11:27:04.680795Z",
     "iopub.status.idle": "2024-10-09T11:27:04.701357Z",
     "shell.execute_reply": "2024-10-09T11:27:04.700394Z",
     "shell.execute_reply.started": "2024-10-09T11:27:04.680795Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_conversational_chain():\n",
    "    prompt_template = \"\"\"\n",
    "    Please extract and summarize the relevant information from the provided context. \n",
    "    Context: \n",
    "    {context}\n",
    "    Question: \n",
    "    {question}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87b38708-a447-4b84-bedc-dd9364e5e76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:27:05.387144Z",
     "iopub.status.busy": "2024-10-09T11:27:05.386584Z",
     "iopub.status.idle": "2024-10-09T11:27:05.400756Z",
     "shell.execute_reply": "2024-10-09T11:27:05.399786Z",
     "shell.execute_reply.started": "2024-10-09T11:27:05.387144Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks = get_text_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f793e096-2780-42d7-bbfc-0ffe9e3184ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:27:05.962591Z",
     "iopub.status.busy": "2024-10-09T11:27:05.961594Z",
     "iopub.status.idle": "2024-10-09T11:27:07.743927Z",
     "shell.execute_reply": "2024-10-09T11:27:07.742934Z",
     "shell.execute_reply.started": "2024-10-09T11:27:05.962591Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_store = get_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43fe4b56-f657-48d0-9a1a-21b4ec0a0aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:27:14.972013Z",
     "iopub.status.busy": "2024-10-09T11:27:14.971017Z",
     "iopub.status.idle": "2024-10-09T11:27:14.985473Z",
     "shell.execute_reply": "2024-10-09T11:27:14.985473Z",
     "shell.execute_reply.started": "2024-10-09T11:27:14.972013Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_input(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    docs = vector_store.similarity_search(user_question)\n",
    "    chain = get_conversational_chain()\n",
    "    \n",
    "    response = chain(\n",
    "        {\"input_documents\":docs,\n",
    "         \"question\": user_question},\n",
    "         return_only_outputs=True\n",
    "    )\n",
    "    print(response[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecea409a-7a59-4be1-b4fb-7afb352a20a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T11:27:15.516932Z",
     "iopub.status.busy": "2024-10-09T11:27:15.516932Z",
     "iopub.status.idle": "2024-10-09T11:27:19.027221Z",
     "shell.execute_reply": "2024-10-09T11:27:19.023771Z",
     "shell.execute_reply.started": "2024-10-09T11:27:15.516932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Castle Swimmer is a webtoon that follows the journey of Siren, a prince who is cursed to live a life of torment. The story explores the themes of prophecy, destiny, and the struggle against fate.\n"
     ]
    }
   ],
   "source": [
    "user_input('What is Castle Swimmer about?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26511df-5d07-409d-95cb-92f888bf7660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
