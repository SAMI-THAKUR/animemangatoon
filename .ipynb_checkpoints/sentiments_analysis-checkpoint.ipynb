{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca847d3-4f3f-4bc2-b305-da7eb74ef5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:44:16.468405Z",
     "iopub.status.busy": "2024-10-09T10:44:16.467897Z",
     "iopub.status.idle": "2024-10-09T10:44:16.475395Z",
     "shell.execute_reply": "2024-10-09T10:44:16.474398Z",
     "shell.execute_reply.started": "2024-10-09T10:44:16.468405Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a3a7d6-9482-4434-a7e0-fb7d88d73ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:45:53.179280Z",
     "iopub.status.busy": "2024-10-09T10:45:53.178279Z",
     "iopub.status.idle": "2024-10-09T10:45:53.200097Z",
     "shell.execute_reply": "2024-10-09T10:45:53.199100Z",
     "shell.execute_reply.started": "2024-10-09T10:45:53.179280Z"
    }
   },
   "outputs": [],
   "source": [
    "def video_comments(video_id):\n",
    "    comments_list = []\n",
    "    replies_list = []\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    video_response = youtube.commentThreads().list(\n",
    "        part='snippet,replies',\n",
    "        videoId=video_id\n",
    "    ).execute()\n",
    "    # Iterate through video response\n",
    "    while video_response:\n",
    "        # Extracting required info from each result object\n",
    "        for item in video_response['items']:\n",
    "            # Extracting comments\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments_list.append(comment)\n",
    "\n",
    "            # Counting the number of replies to the comment\n",
    "            replycount = item['snippet']['totalReplyCount']\n",
    "\n",
    "            # If there are replies, extract them\n",
    "            if replycount > 0:\n",
    "                # Iterate through all replies\n",
    "                for reply in item['replies']['comments']:\n",
    "                    # Extract reply\n",
    "                    reply_text = reply['snippet']['textDisplay']\n",
    "                    # Append reply to the list of replies\n",
    "                    replies_list.append(reply_text)\n",
    "\n",
    "        # Check for the next page\n",
    "        if 'nextPageToken' in video_response:\n",
    "            next_page_token = video_response['nextPageToken']\n",
    "            video_response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "        else:\n",
    "            break\n",
    "    # Create a DataFrame from the lists\n",
    "    df = pd.DataFrame({'comments': comments_list})\n",
    "    # Save the DataFrame to a CSV file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "588045fb-8714-4ac0-a607-e6b01815209e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:44:48.226011Z",
     "iopub.status.busy": "2024-10-09T10:44:48.226011Z",
     "iopub.status.idle": "2024-10-09T10:44:48.242005Z",
     "shell.execute_reply": "2024-10-09T10:44:48.241004Z",
     "shell.execute_reply.started": "2024-10-09T10:44:48.226011Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae2ae2c-0eda-43f2-9742-6b0bbbf3fae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:44:48.585061Z",
     "iopub.status.busy": "2024-10-09T10:44:48.585061Z",
     "iopub.status.idle": "2024-10-09T10:44:48.602339Z",
     "shell.execute_reply": "2024-10-09T10:44:48.601339Z",
     "shell.execute_reply.started": "2024-10-09T10:44:48.585061Z"
    }
   },
   "outputs": [],
   "source": [
    "#create function to get subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#create function to get polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94239ef4-4428-4c99-947b-c267217c3053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
